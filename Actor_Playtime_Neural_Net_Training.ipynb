{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Actor_Playtime_Neural_Net_Training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oixansAmkfM"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhw9gC8SDhP9"
      },
      "source": [
        "import cv2     # for capturing videos\n",
        "import math   # for mathematical operations\n",
        "import matplotlib.pyplot as plt    # for plotting the images\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "from keras.preprocessing import image   # for preprocessing the images\n",
        "import numpy as np    # for mathematical operations\n",
        "from keras.utils import np_utils\n",
        "from skimage.transform import resize   # for resizing images"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PwdhINXpbQI"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mx_PKONXD10_",
        "outputId": "de6d5687-87f6-4709-ffcc-29091300ee7f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGbxtAMLDr8d",
        "outputId": "94264486-5852-4901-8754-ce3a57b0b66c"
      },
      "source": [
        "count = 0\n",
        "videoFile = \"/content/drive/MyDrive/Shou_Trumana_Kinosimka.RU (online-video-cutter.com).mp4\"\n",
        "cap = cv2.VideoCapture(videoFile)   # capturing the video from the given path\n",
        "frameRate = cap.get(5) #frame rate\n",
        "x=1\n",
        "while(cap.isOpened()):\n",
        "    frameId = cap.get(1) #current frame number\n",
        "    ret, frame = cap.read()\n",
        "    if (ret != True):\n",
        "        break\n",
        "    if (frameId % math.floor(frameRate) == 0):\n",
        "        filename =\"frame%d.jpg\" % count;count+=1\n",
        "        cv2.imwrite(filename, frame)\n",
        "cap.release()\n",
        "print (\"Done!\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C82I4IQUEYIf"
      },
      "source": [
        "i = 0 # i did this to do the mapping file in order to teach the neural net\n",
        "while i < 301:\n",
        "  i=str(i)\n",
        "  img = plt.imread('frame'+i+'.jpg')   # reading image using its name\n",
        "  print('frame',i,':')\n",
        "  plt.imshow(img)\n",
        "  plt.show()\n",
        "  i=int(i)\n",
        "  i+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "DNPBhRWghaXT",
        "outputId": "a515c238-766c-423e-c680-08c3f21e719f"
      },
      "source": [
        "data = pd.read_csv('mapping.csv')     # reading the csv file\n",
        "data.head()      # printing first five rows of the file"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image_ID</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>frame0.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>frame1.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>frame2.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>frame3.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>frame4.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Image_ID  Class\n",
              "0  frame0.jpg      0\n",
              "1  frame1.jpg      0\n",
              "2  frame2.jpg      0\n",
              "3  frame3.jpg      0\n",
              "4  frame4.jpg      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WwfAbSvLVPF"
      },
      "source": [
        "X = [ ]     # creating an empty array\n",
        "for img_name in data.Image_ID:\n",
        "    img = plt.imread('' + img_name)\n",
        "    X.append(img)  # storing each image in array X\n",
        "X = np.array(X)    # converting list to array"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4uWPF75LYvi"
      },
      "source": [
        "y = data.Class\n",
        "dummy_y = np_utils.to_categorical(y)    # one hot encoding Classes"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MCgp5PxLbOw"
      },
      "source": [
        "image = []\n",
        "for i in range(0,X.shape[0]):\n",
        "    a = resize(X[i], preserve_range=True, output_shape=(224,224)).astype(int)      # reshaping to 224*224*3\n",
        "    image.append(a)\n",
        "X = np.array(image)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRaoi8aVLfwF"
      },
      "source": [
        "from keras.applications.vgg16 import preprocess_input\n",
        "X = preprocess_input(X) "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Z0xpHNSL_AZ"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, dummy_y, test_size=0.3, random_state=42)    # preparing the validation set"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ych2FyusMCL4"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.layers import Dense, InputLayer, Dropout"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyhNeHI0MFDI",
        "outputId": "39322aaf-f0a6-4177-cabf-6a74be5248a4"
      },
      "source": [
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))    # include_top=False to remove the top layer"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "58900480/58889256 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7JORmwLMIho",
        "outputId": "11738258-d9b5-4889-ffb2-dfc114ca2480"
      },
      "source": [
        "X_train = base_model.predict(X_train)\n",
        "X_valid = base_model.predict(X_valid)\n",
        "X_train.shape, X_valid.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((208, 7, 7, 512), (90, 7, 7, 512))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZv9BVUmMLOv"
      },
      "source": [
        "X_train = X_train.reshape(208, 7*7*512)      # converting to 1-D\n",
        "X_valid = X_valid.reshape(90, 7*7*512)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wok0-iQxMN0l"
      },
      "source": [
        "train = X_train/X_train.max()      # centering the data\n",
        "X_valid = X_valid/X_train.max()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gH34OnVMQn5"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(InputLayer((7*7*512,)))    # input layer\n",
        "model.add(Dense(units=1024, activation='sigmoid')) # hidden layer\n",
        "model.add(Dense(2, activation='softmax'))    # output layer"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3NMWNk1MUPW"
      },
      "source": [
        "# ii. Compiling the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNOQJLzpMXPu",
        "outputId": "1e63c5d6-57d4-4ba7-ffee-9878e8cf79f2"
      },
      "source": [
        "# iii. Training the model\n",
        "model.fit(train, y_train, epochs=10, validation_data=(X_valid, y_valid))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "7/7 [==============================] - 10s 230ms/step - loss: 0.6699 - accuracy: 0.6127 - val_loss: 0.3571 - val_accuracy: 0.8667\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 1s 153ms/step - loss: 0.1609 - accuracy: 0.9596 - val_loss: 0.2710 - val_accuracy: 0.8444\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 1s 158ms/step - loss: 0.0640 - accuracy: 0.9943 - val_loss: 0.2591 - val_accuracy: 0.8556\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 1s 155ms/step - loss: 0.0416 - accuracy: 1.0000 - val_loss: 0.2635 - val_accuracy: 0.8667\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 1s 154ms/step - loss: 0.0245 - accuracy: 1.0000 - val_loss: 0.2338 - val_accuracy: 0.8667\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 1s 153ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.2479 - val_accuracy: 0.8778\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 1s 153ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.2761 - val_accuracy: 0.8778\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 1s 155ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.2922 - val_accuracy: 0.8667\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 1s 155ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.2888 - val_accuracy: 0.8667\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 1s 153ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.2640 - val_accuracy: 0.8667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0f4e66b8d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    }
  ]
}